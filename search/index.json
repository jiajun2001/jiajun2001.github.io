[{"content":"Upon completing my penultimate year of studying for a Bachelor of Computer Science at the University of Adelaide, I was fortunate to be awarded the Adelaide Summer Research Scholarship for the period of 2022-2023. Delving into a 6-week research project, I collaborated with my research partner, Jian Zhe Chan, while being guided by the experienced supervision of Dr. Cruz Izu and Dr. Amali Weerasinghe.\nOur research endeavor aimed to facilitate the utilization of code quality feedback tools for novice programmers. The culmination of our efforts resulted in the development of \u0026ldquo;CPPAnalyzer\u0026rdquo;, a C++ code quality checker tailored explicitly for novice programmers. This tool serves as a valuable resource to enhance coding style and foster good programming habits among beginners.\nIn this post, I am delighted to present a comprehensive summary of our research and serve as a documentation guide for using the \u0026ldquo;CPPAnalyzer\u0026rdquo; code quality checker. Our hope is that this tool will be a stepping stone for aspiring programmers to sharpen their skills and embark on a journey of coding excellence.\nResearch Topic Facilitate the use of code quality feedback tools for novice programmers Supervisors Dr Cruz Izu Lecturer School of Computer and Mathematical Sciences, Faculty of Sciences, Engineering and Technology Research Interests: Computer System Architecture, Higher Education, Networking and Communications, Teacher Education and Professional Development of Educators Dr Amali Weerasinghe School of Computer and Mathematical Sciences, Faculty of Sciences, Engineering and Technology Research Interests: Artificial Intelligence Student Researchers Jiajun Yu (Jason) Bachelor of Computer Science Interests: Computer Systems, Computer Architecture, Algorithms, Data Structures Email: jiajun.yu@student.adelaide.edu.au Blog: https://jiajun2001.github.io/ Jian Zhe Chan (JZ) Bachelor of Computer Science Interests: System Programming, Competitive Programming, Computer Networks and Applications, Parallel and Distributed Systems Email: jianzhe.chan@student.adelaide.edu.au Blog: https://chan-jz.github.io/ Summer Research Outcome Familiarized with the use and features of two code quality checking tools. Used BASH scripts and Python programs to analyze two code quality checking tools (Pylint and Hyperstyle) outputs generated from codes submitted by students (Jupyter Notebook, Python, Java files), and used excel to visualize the data. Developed a tool to filter Pylint error codes in groups for teaching and researching purposes. Developed a tool (CPPAnalyzer) to pick up code smells that are missed by existing code quality checking tools About CPPAnalyzer CPPAnalyzer is a code quality checking tool that is developed by Jiajun Yu and Jian Zhe Chan under the supervison of Dr Cruz Izu and Dr Amali Weerasinghe during the summer of 2022-2023. It is aimed to analyze the code quality of C++ programs submitted by novice programmers and detect or pick up details missed by existing tools to help students have good coding styles and habits. Originally, CPPAnalyzer was planned and desigend to detect 10 rules (FYI: Summer-Research/CPPAnalyzer/Refactor_patterns.pdf). However, due to the time constraint and other unexpected situations, JZ and me only finished implementing 6 rules, they were: Refactor Rule 1: Simplify Boolean Expression Refactor Rule 2: Simplify Boolean Return Refactor Rule 3: Collapsible Nested if Statement Refactor Rule 8: Empty if Statement Refactor Rule 9: Dead Code And the rest unimplemented refactor rules are: Refactor Rule 4: Consolidate Conditional Expressions Refactor Rule 5: Redundant Conditional Check Refactor Rule 6: No Use of Else Refactor Rule 7: Duplicate if-else Body In general, CPPAnalyzer is written in Python and it detects broken rules by checking all related nodes (if nodes, while nodes, for nodes, etc). We collect those nodes in JSON format which come from the abstract syntax trees of authentic student submissions generated by clang compiler. Let\u0026rsquo;s run CPPAnalyzer Clone this github repository using the following command 1 git clone --recursive https://github.com/jiajun2001/Summer-Research.git Go to CPPAnalyzer using the following command 1 cd CPPAnalyzer 3: We have provided you with some test cases in the CPPAnalyzer folder Examples: test_Rule3.cpp, test_Rule8.cpp, test_Rule9.cpp, test_Rule123.cpp 4: If you want to play around with them, firstly open ASTProcessor.py file. This is the entry point of our CPPAnalyzer. 5: Modify line 9 to specify your input file (by default, the input C++ file for testing is test_Rule123.cpp) fileName = \u0026quot;test_Rule123.cpp\u0026quot; 6: Now we can run the program by simply entering the following command: 1 python ASTProcessor.py 7: If this command does not work, try this command: 1 python3 ASTProcessor.py If this still does not work, you can check your environment to see if you have properly installed Python or not. 8: Have great fun! If you follow the steps above correctly, you should technically see something like this in your terminal: 1 2 3 4 5 6 7 8 9 10 (base) apple@student-10-201-17-110 CPPAnalyzer % python3 ASTProcessor.py test_Rule123.cpp:13:9: RRE001: No need to check if Boolean variable or expression is equal to true or false (Simplify Boolean Expression) test_Rule123.cpp:19:12: RRE001: No need to check if Boolean variable or expression is equal to true or false (Simplify Boolean Expression) test_Rule123.cpp:19:27: RRE001: No need to check if Boolean variable or expression is equal to true or false (Simplify Boolean Expression) test_Rule123.cpp:20:19: RRE001: No need to check if Boolean variable or expression is equal to true or false (Simplify Boolean Expression) test_Rule123.cpp:20:35: RRE001: No need to check if Boolean variable or expression is equal to true or false (Simplify Boolean Expression) test_Rule123.cpp:20:51: RRE001: No need to check if Boolean variable or expression is equal to true or false (Simplify Boolean Expression) test_Rule123.cpp:13:5: RRE003: Avoiding deep nested ifs by using and (\u0026amp;\u0026amp;) operator test_Rule123.cpp:21:13: RRE009A: Detected code that is never executed below the current return/continue/return statement (base) apple@student-10-201-17-110 CPPAnalyzer % How does this work? This is the structure of CPPAnalyzer: Workflow of CPPAnalyzer\nASTProcessor.py is the entry point of CPPAnalyzer. This file allows you to specify your input file (C++ program that you are going to analyze), and contains other collectors and rule detectors. If you are going to extend CPPAnalyzer, you should include and invoke your rule detectors in this file. In this file, we will also invoke a module called HeaderPreprocessor before calling collectors and rule detectors. When we are generating the AST (abstract syntax tree), we do not want the tree to include any libraries. Otherwise, the tree structure will be giant and messy and this does not help us analyze the code structure. Therefore, we used this module to disable any library that the author of the program included before. The idea here is by putting a line of mark code int XX_MARKER_XX; to indicate where should we start collecting useful subroutine(function) nodes. Under Tools folder, we have a folder for collectors and another folder for detectors. Technically, at first, we would invoke detectors in consecutive order (Rule1Detector -\u0026gt; Rule2Detector -\u0026gt; Rule3Detector\u0026hellip;) For each rule detector, it will invoke collectors to collect JSON nodes needed from the AST (abstract syntax tree) and store those JSON nodes in temp folder. For your reference, if you want to have a look at the AST generated, you could use the following command to dump one in temp folder. 1 clang -Xclang -ast-dump=json -fsyntax-only -fno-color-diagnostics test_Rule123.cpp \u0026gt; temp/output.json After obtaining all nodes we need for detecting one rule, we could start coding the main logic for checking if the node breaks the rule or not. The general ideas here is to run a for loop to check each relative node that we collected before. Since code structure can sometimes be nested, so we used a few recursive functions (DFS and BFS) to analyze a single node. Genuine Advice Try to let the program run first and play around with it by changing the input code to see what will the terminal generate. When you are extending this project, try to use some very simple test cases and see the structures of the AST (abstract syntax tree) generated and nodes colleted by collectors. It is important to be familiar with the JSON files generated. You could use some online JSON parsers to visualize the structure. Consolidate your knowledge about tree data structure and tree traversal algorithms. Knowing these knowledge is of vital importance for further developing the project. We might be wrong in some stages of programming this CPPAnalyzer, so feel free to apply your own ideas and change some existing code. Good luck! ","date":"2023-07-08T17:11:55+10:30","image":"https://jiajun2001.github.io/p/adelaide-summer-research-project/structure_hu_dc636b50329a9317.png","permalink":"https://jiajun2001.github.io/p/adelaide-summer-research-project/","title":"Adelaide Summer Research Project"},{"content":"Complexity The worst-case complexity of the algorithm is the function defined by the maximum number of steps taken in any instance of size n.\nThe best-case complexity of the algorithm is the function defined by the minimum number of steps taken in any instance of size n.\nThe average-case complexity of the algorithm is the function defined by the average number of steps over all instances of size n.\nBig O Notation The big O notation simplifies analysis by ignoring levels of detail that do not impact the comparison of algorithms.\nTwo Types of Data Structures Contiguously-allocated structures are composed of single slabs of memory, and include arrays, matrices, heaps and hash tables.\nAdvantages: Constant-time access | Space efficiency | Memory locality Linked data structures are composed of distinct chunks of memory bound together by pointers, and include lists, trees, and graph adjacency lists.\nAdvantage: More freedom | Simpler insertions and deletions | Moving pointers is easier and faster Arrays Operation Unsorted Array Sorted Array Search(L, k) O(n) O(logn) Insert(L, x) O(1) O(n) Delete(L, x) O(1) O(n) Successor(L, x) O(n) O(1) Predecessor(L, x) O(n) O(1) Minimum(L) O(n) O(1) Maximum(L) O(n) O(1) When deleting an element x from an unsorted array with size n, we can write over array\\[x\\] with array[n], and decrement n. Linked List Operation Singly Unsorted List Doubly Unsorted List Singly Sorted List Doubly Sorted List Search(L, k) O(n) O(n) O(n) O(n) Insert(L, x) O(1) O(1) O(n) O(n) Delete(L, x) O(n) O(1) O(n) O(1) Successor(L, x) O(n) O(n) O(1) O(1) Predecessor(L, x) O(n) O(n) O(n) O(1) Minimum(L) O(n) O(n) O(1) O(1) Maximum(L) O(n) O(n) O(1) O(1) For deletion, assume we are given a pointer x to the item to be deleted. However, we actually need a pointer to the element pointing to x in the list. Therefore, the deletion time complexity for doubly linked list is always O(1).\nTo find the maximum element in a singly sorted list, we can maintain a separate pointer to the list tail. This will not change the cost for deletion.\nImplementation of singly linked list 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 class Node { int val; Node next; Node(int val) { this.val = val; } } class MyLinkedList { int size; Node dummyHead; public MyLinkedList() { size = 0; dummyHead = new Node(0); } public int get(int index) { if (index \u0026lt; 0 || index \u0026gt;= size) return -1; Node currentNode = dummyHead; for (int i = 0; i \u0026lt;= index; i++) { currentNode = currentNode.next; } return currentNode.val; } public void addAtHead(int val) { Node currentNode = dummyHead; Node newNode = new Node(val); newNode.next = currentNode.next; currentNode.next = newNode; size++; } public void addAtTail(int val) { Node currentNode = dummyHead; for (int i = 0; i \u0026lt; size; i++) { currentNode = currentNode.next; } Node newNode = new Node(val); currentNode.next = newNode; size++; } public void addAtIndex(int index, int val) { if (index \u0026lt; 0 || index \u0026gt; size) return; Node currentNode = dummyHead; for (int i = 0; i \u0026lt; index; i++) { currentNode = currentNode.next; } Node newNode = new Node(val); newNode.next = currentNode.next; currentNode.next = newNode; size++; } public void deleteAtIndex(int index) { if (index \u0026lt; 0) index = 0; if (index \u0026gt;= size) return; Node currentNode = dummyHead; for (int i = 0; i \u0026lt; index; i++) { currentNode = currentNode.next; } currentNode.next = currentNode.next.next; size--; } } Implementation of doubly linked list 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 class Node { int val; Node prev, next; Node(int val) { this.val = val; } } class MyLinkedList { int size; Node dummyHead; Node dummyTail; public MyLinkedList() { size = 0; dummyHead = new Node(0); dummyTail = new Node(0); dummyHead.next = dummyTail; dummyTail.prev = dummyHead; } public int get(int index) { if (index \u0026lt; 0 || index \u0026gt;= size) return -1; Node currentNode; if (index \u0026gt;= size / 2) { currentNode = dummyTail; for (int i = 0; i \u0026lt; size - index; i++) { currentNode = currentNode.prev; } } else { currentNode = dummyHead; for (int i = 0; i \u0026lt;= index; i++) { currentNode = currentNode.next; } } return currentNode.val; } public void addAtHead(int val) { Node currentNode = dummyHead; Node newNode = new Node(val); newNode.next = currentNode.next; newNode.next.prev = newNode; currentNode.next = newNode; newNode.prev = currentNode; size++; } public void addAtTail(int val) { Node currentNode = dummyTail; Node newNode = new Node(val); newNode.prev = currentNode.prev; newNode.prev.next = newNode; currentNode.prev = newNode; newNode.next = currentNode; size++; } public void addAtIndex(int index, int val) { if (index \u0026lt; 0 || index \u0026gt; size) return; Node currentNode; if (index \u0026gt;= size / 2) { currentNode = dummyTail; for (int i = 0; i \u0026lt; size - index + 1; i++) { currentNode = currentNode.prev; } } else { currentNode = dummyHead; for (int i = 0; i \u0026lt; index; i++) { currentNode = currentNode.next; } } Node newNode = new Node(val); newNode.next = currentNode.next; newNode.next.prev = newNode; currentNode.next = newNode; newNode.prev = currentNode; size++; } public void deleteAtIndex(int index) { if (index \u0026lt; 0 || index \u0026gt;= size) return; Node currentNode; if (index \u0026gt;= size / 2) { currentNode = dummyTail; for (int i = 0; i \u0026lt; size - index; i++) { currentNode = currentNode.prev; } } else { currentNode = dummyHead; for (int i = 0; i \u0026lt;= index; i++) { currentNode = currentNode.next; } } currentNode.next.prev = currentNode.prev; currentNode.prev.next = currentNode.next; size--; } } Implementation of Binary Search Tree 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 class Node { int val; Node left, right; public Node(int val) { this.val = val; left = right = null; } } class BST { Node root; // Insert elements public Node insert(Node current, int val) { if (current == null) return new Node(val); if (val \u0026lt; current.val) { current.left = insert(current.left, val); } else if (val \u0026gt; current.val) { current.right = insert(current.right, val); } return current; } // Insert Helper Function public void insertHelper(int val) { root = insert(root, val); } // Search Function public boolean search(Node current, int val) { if (current == null) return false; if (current.val == val) return true; if (val \u0026lt; current.val) { return search(current.left, val); } else { return search(current.right, val); } } // Search Helper Function public void searchHelper(int val) { System.out.println(search(root, val)); } // FindMax function public Node findMax(Node current) { while (current.right != null) { current = current.right; } return current; } // Delete Function public Node delete(Node current, int val) { if (current == null) return null; if (val \u0026lt; current.val) { current.left = delete(current.left, val); } else if (val \u0026gt; current.val) { current.right = delete(current.right, val); } else { if (current.left == null \u0026amp;\u0026amp; current.right == null) { current = null; } else if (current.left == null) { current = current.right; } else if (current.right == null) { current = current.left; } else { Node temp = findMax(current.left); current.val = temp.val; current.left = delete(current.left, temp.val); } } return current; } // Delete Helper Function public void deleteHelper(int val) { root = delete(root, val); } // InOrder Traversal public void InOrder(Node current) { if (current == null) return; InOrder(current.left); System.out.print(current.val + \u0026#34; \u0026#34;); InOrder(current.right); } } Hashing Tables Closed addressing hashing (Open Hashing) handles collision by storing all elements with the same hashed key in one table entry.\nOpen addressing hashing (Closed Hashing) handles collision by storing subsequent elements with the same hashed key in different table entries.\nOperation Hash Table (expected) Hash Table (worst case) Search(L, k) O(n/m) O(n) Insert(L, x) O(1) O(1) Delete(L, x) O(1) O(1) Successor(L, x) O(n+m) O(n+m) Predecessor(L, x) O(n+m) O(n+m) Minimum(L) O(n+m) O(n+m) Maximum(L) O(n+m) O(n+m) Using chaining with doubly-linked lists to resolve collisions in an m-elements hash table with n items Heap Heap is a simple and elegant data structure for efficient supporting the priority queue operations insert and extract-min/max. They work by maintaining a partial order on the set of elements which is weaker than the sorted order.\nA heap-labeled tree is defined to be a binary tree such that the key labeling of each node dominates the key labeling of each of its children.\nIn a min-heap, a node dominates its children by containing a smaller key than they do.\nIn a max-heap, parent nodes dominate by begin bigger.\nHeaps are mostly used to implement Priority Queues.\nHeap Implementation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 import java.util.Arrays; public class MinHeap { int size; int maxSize; int[] heap; MinHeap(int maxSize) { if (maxSize \u0026lt;= 0) return; this.maxSize = maxSize; this.size = 0; this.heap = new int[maxSize + 1]; Arrays.fill(heap, Integer.MAX_VALUE); this.heap[0] = Integer.MIN_VALUE; } MinHeap(int maxSize,int[] arr) { if (arr.length \u0026gt; maxSize) return; this.maxSize = maxSize; this.size = arr.length; this.heap = new int[maxSize + 1]; Arrays.fill(heap, Integer.MAX_VALUE); this.heap[0] = Integer.MIN_VALUE; for (int i = 0; i \u0026lt; arr.length; i++) { this.heap[i + 1] = arr[i]; } buildHeap(); } int parent(int pos) { return pos / 2; } int leftChild(int pos) { return pos * 2; } int rightChild(int pos) { return pos * 2 + 1; } boolean isLeaf(int pos) { return pos \u0026gt; size / 2 \u0026amp;\u0026amp; pos \u0026lt;= size; } void swap(int pos1, int pos2) { int temp = heap[pos1]; heap[pos1] = heap[pos2]; heap[pos2] = temp; } void minHeapify(int pos) { if (!isLeaf(pos)) { if (heap[pos] \u0026gt; heap[leftChild(pos)] || heap[pos] \u0026gt; heap[rightChild(pos)]) { int smallerElementIndex = heap[leftChild(pos)] \u0026lt; heap[rightChild(pos)] ? leftChild(pos) : rightChild(pos); swap(pos, smallerElementIndex); minHeapify(smallerElementIndex); } } } void insert(int element) { if (size \u0026gt;= maxSize) return; heap[++size] = element; int current = size; while (heap[parent(current)] \u0026gt; heap[current]) { swap(parent(current), current); current = parent(current); } } void buildHeap() { for (int i = size / 2; i \u0026gt;= 1; i--) { minHeapify(i); } } void removeMin() { if (size == 0) return; heap[1] = heap[size]; heap[size--] = Integer.MAX_VALUE; minHeapify(1); } // Function to print the contents of the heap void display() { if (size == 0) { System.out.println(\u0026#34;Empty Heap!\u0026#34;); return; } System.out.println(\u0026#34;PARENT\u0026#34; + \u0026#34;\\t\u0026#34; + \u0026#34;LEFT\u0026#34; + \u0026#34;\\t\u0026#34; + \u0026#34;RIGHT\u0026#34;); if (size == 1) { System.out.println(\u0026#34; \u0026#34; + heap[1] + \u0026#34;\\t\\t\u0026#34;); return; } for (int i = 1; i \u0026lt;= size / 2; i++) { System.out.print(\u0026#34; \u0026#34; + heap[i] + \u0026#34;\\t\\t\u0026#34; + heap[2 * i] + \u0026#34;\\t\\t\u0026#34; + heap[2 * i + 1]); System.out.println(); } } } When passing parameters into the function of \u0026lsquo;swap(int pos1, int pos2)\u0026rsquo;, we must be aware that the function handles indices instead of elements. Runtime of Heap Operations Operation Runtime Find the minimum element O(1) Delete minimum element O(logn) Insert an element O(logn) Build a heap O(n) Heap Sort Build the heap for n elements in time O(n)\nEach step picks and deletes the minimum element in time O(logn)\nIterate until the heap is empty.\nIn total n iterations implies a total runtime of O(nlogn)\nSelection Sort 1 2 3 4 5 6 7 8 9 10 11 private static void selection(int[] array) { for (int i = 0; i \u0026lt; array.length - 1; i++) { int min = i; for (int j = i + 1; j \u0026lt; array.length; j++) { if (array[j] \u0026lt; array[min]) min = j; } int temp = array[i]; array[i] = array[min]; array[min] = temp; } } Insertion Sort 1 2 3 4 5 6 7 8 9 10 11 private static void InsertionSort(int[] array) { for (int i = 1; i \u0026lt; array.length; i++) { int j = i; while (j \u0026gt; 0 \u0026amp;\u0026amp; array[j - 1] \u0026gt; array[j]) { int temp = array[j]; array[j] = array[j - 1]; array[j - 1] = temp; j--; } } } Merge Sort Merge sort involves partitioning the elements into two groups, sorting each of the smaller problems recursively, and then interleaving the two sorted lists to totally order the elements. It is a classic divide-and-conquer algorithm but its primary disadvantage is the need for an auxiliary array when sorting arrays.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 import java.util.ArrayList; import java.util.Arrays; public class MergeSort { public ArrayList\u0026lt;Integer\u0026gt; mergeSort(ArrayList\u0026lt;Integer\u0026gt; myArr) { if (myArr.size() == 1) return myArr; int mid = myArr.size() / 2; ArrayList\u0026lt;Integer\u0026gt; left = new ArrayList\u0026lt;Integer\u0026gt;(); ArrayList\u0026lt;Integer\u0026gt; right = new ArrayList\u0026lt;Integer\u0026gt;(); for (int i = 0; i \u0026lt; mid; i++) { left.add(myArr.get(i)); } for (int i = mid; i \u0026lt; myArr.size(); i++) { right.add(myArr.get(i)); } ArrayList\u0026lt;Integer\u0026gt; lSplit = mergeSort(left); ArrayList\u0026lt;Integer\u0026gt; rSplit = mergeSort(right); return merge(lSplit, rSplit); } public ArrayList\u0026lt;Integer\u0026gt; merge(ArrayList\u0026lt;Integer\u0026gt; left, ArrayList\u0026lt;Integer\u0026gt; right) { int i = 0; int j = 0; ArrayList\u0026lt;Integer\u0026gt; outcome = new ArrayList\u0026lt;Integer\u0026gt;(); while (i \u0026lt; left.size() \u0026amp;\u0026amp; j \u0026lt; right.size()) { if (left.get(i) \u0026lt; right.get(j)) { outcome.add(left.get(i++)); } else { outcome.add(right.get(j++)); } } while (i \u0026lt; left.size()) { outcome.add(left.get(i++)); } while (j \u0026lt; right.size()) { outcome.add(right.get(j++)); } return outcome; } } Quick Sort 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 import java.util.ArrayList; import java.util.Arrays; import java.util.Collections; public class QuickSort { int partition(ArrayList\u0026lt;Integer\u0026gt; arr, int start, int end) { int pivot = arr.get(end); int index = start; for (int i = start; i \u0026lt; end; i++) { if (arr.get(i) \u0026lt; pivot) { Collections.swap(arr, i, index); index++; } } Collections.swap(arr, index, end); return index; } void quickSort(ArrayList\u0026lt;Integer\u0026gt; arr, int start, int end) { if (start \u0026lt; end) { int partition = partition(arr, start, end); quickSort(arr, start, partition - 1); quickSort(arr, partition + 1, end); } } } Topological Sort 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 public class TopologicalSort { HashSet\u0026lt;Integer\u0026gt; visited; LinkedList\u0026lt;Integer\u0026gt;[] adjacencyList; LinkedList\u0026lt;Integer\u0026gt; myStack; int nodeNum; public TopologicalSort(int nodeNum) { visited = new HashSet\u0026lt;\u0026gt;(); adjacencyList = new LinkedList[nodeNum]; for (int i = 0; i \u0026lt; nodeNum; i++) { adjacencyList[i] = new LinkedList\u0026lt;\u0026gt;(); } myStack = new LinkedList\u0026lt;\u0026gt;(); this.nodeNum = nodeNum; } public void sort() { for (int i = 0; i \u0026lt; nodeNum; i++) { if (!visited.contains(i)) { sortUntil(i); } } } public void sortUntil(int node) { visited.add(node); for (int n : adjacencyList[node]) { if (!visited.contains(n)) { sortUntil(n); } } myStack.push(node); } public void addEdge(int parent, int child) { adjacencyList[parent].add(child); } } Backtracking Backtracking is a systematic way to iterate through all the possible configurations of a search space. These configuration may represent all possible arrangements of objects. Backtracking ensures correctness by enumerating all possibilities. It ensures efficiency by never visiting a state more than once. Dynamic Programming Dynamic programming gives us a way to design custom algorithms that systematically search all possibilities while storing results to avoid recomputimg. By storing the consequences of all possible decisions and using this information in a systematic way, the total amount of work is minimized. Essentially, dynamic programming is a trade off of space for time. Trie Trie is a tree data structure used for locating specific keys from a set. It is also known as prefix tree or digital tree.\nTrie can be used to build Auto-complete and Spell-checker.\nIt allows efficient storage of words with common prefixes. Each node in a trie represents a character in the string and also indicates the termination of the string.\nThere are three main functions: insert(word), search(word), startsWith(word).\nMain advantage of trie: startsWith() is very efficient.\nThe time complexity of insert, search and startWith are all O(k), where k is the length of the string.\nImplementation\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 class Node { HashMap\u0026lt;Character, Node\u0026gt; children; boolean endOfWord; Node() { this.children = new HashMap\u0026lt;Character, Node\u0026gt;(); this.endOfWord = false; } } class Trie { Node root; public Trie() { root = new Node(); } public void insert(String word) { Node cur = root; for (int i = 0; i \u0026lt; word.length(); i++) { char c = word.charAt(i); if (!cur.children.containsKey(c)) { cur.children.put(c, new Node()); } cur = cur.children.get(c); } cur.endOfWord = true; } public boolean search(String word) { Node cur = root; for (int i = 0; i \u0026lt; word.length(); i++) { char c = word.charAt(i); if (!cur.children.containsKey(c)) return false; cur = cur.children.get(c); } return cur.endOfWord; } public boolean startsWith(String prefix) { Node cur = root; for (int i = 0; i \u0026lt; prefix.length(); i++) { char c = prefix.charAt(i); if (!cur.children.containsKey(c)) return false; cur = cur.children.get(c); } return true; } } Amortized Analysis Amortized analysis is used for algorithms where an occasional operation is very slow, but most of the other operations are faster. In amortized analysis, we analyze a sequence of operations and guarantee a worst-case average time that is lower than the worst case of a particular expensive operation. (GeeksforGeeks)\nA good example is to analyze the dynamic array. For dynamic array, we need to double the size of the array whenever it becomes full. If the array becomes full, we need to allocate memory for larger array size, typically twice the old array, copy the contents of the old array to a new array, and free the old array. All of the steps above can take O(n). If we use simple analysis, we can draw the conclusion that the worst-case cost of n insertions is n * O(n) which is O(n^2). This analysis gives an upper bound, but not a tight upper bound for n insertions as all insertions don’t take Θ(n) time.\nHowever, by using amortized analysis, we list the cost of inserting each element and divide the sum of the insertion cost by the total number of insertions, we can get the amortized cost and find that the time complexity of dynamic array insertion is actually O(1).\nBit Manipulation Shifting For positive numbers:\nLeft Shift: Multiplying a number by 2. Right Shift: Divide a number by 2 (Round Down: 3 -\u0026gt; 1) For negative numbers:\nLogical Right Shift: Adding 0 in front (Get a meaningless number). Arithmatic Right Shift: Adding its original sign bit in front (Round Down: -5 -\u0026gt; -3). Masking Get c-th bit: ((1 \u0026laquo; c) \u0026amp; x) != 0 Set c-th bit to be 1: (1 \u0026laquo; c) | x Set c-th bit to be 0: (~(1 \u0026laquo; c)) \u0026amp; x Singleton Design Pattern Singleton design pattern is used when we need to ensure that only one object of a particular class need to be created. All further reference to this object are referred to the same underlying instance created.\nSingleton classes are used for logging, driver objects, caching and thread pool, database connections.\nIssues: Coupling issue / Concurrency issue\nFactory Design Pattern Factory design pattern deals with the problem of creating objects without having to specify the exact class of the object that will be created. This is done by creating objects by calling a factory method.\nWe use it when a method returns one of several possible classes that share a common parent class.\nAll potential classes are in the same subclass hierarchy.\nUnion Find A disjoint-set data structure is defined as a data structure that keeps track of set of elements partitioned into a number of disjoint subsets.\nA union-find algorithm is an algorithm that performs two useful operations on such a data structure:\nFind: Determine which subset a particular element is in. This can also be used for determining if two elements are in the same subset. Union: Join two subsets into a single subset. For naïve linking, a Union or Find operation can take O(n) time in the worst case, where n is the number of elements.\nProof: Find takes proportional time to the height of the tree. In the worst case, the tree can be degenerated to a list. Union(1, 2), Union(2, 3), Union(3, 4)\u0026hellip;.. QuickSelect Quick Select can be used to find the k-th largest element in an array with time complexity of O(n).\nThe average time complexity is O(n)\nAssume we keep on executing quick select on half of the array: n + (n / 2) + (n / 4) + \u0026hellip; = 2n The worst case time complexity is O(n^2)\nAssume each quick select we can only eliminate one element, therefore, we need to run the algorithm n times 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public int findKthLargest(int[] nums, int k) { return quickSelect(nums, 0, nums.length - 1, nums.length - k); } public void swap(int[] nums, int left, int right) { int temp = nums[left]; nums[left] = nums[right]; nums[right] = temp; } public int quickSelect(int[] nums, int left, int right, int k) { int ptr = left; int pivot = nums[right]; for (int i = left; i \u0026lt; right; i++) { if (nums[i] \u0026lt; pivot) { swap(nums, i, ptr); ptr++; } } swap(nums, ptr, right); if (k \u0026lt; ptr) return quickSelect(nums, left, ptr - 1, k); if (k \u0026gt; ptr) return quickSelect(nums, ptr + 1, right, k); return nums[k]; } Balanced Binary Search Tree AVL Tree (Adelson-Velsky and Landis Tree)\nIt is a self-balancing binary search tree. In an AVL tree, the heights of the two child subtrees of any node differ by at most one. If at any time they differ by more than one, re-balancing is done to restore this property. Search / Delete / Insert: O(logn) Red Black Tree\nA node is either red or black. The root and leaves (NIL) are black. All paths from a node to its NIL descendants contain the same number of black nodes. The longest path is no more than twice the length of the shortest path. Search / Delete / Insert: O(logn) Red Black Trees provide faster insertion and removal operations than AVL trees as fewer rotations are done due to relatively relaxed balancing.\nReference GeeksforGeeks 2022, Introduction to Amortized Analysis, GeeksforGeeks, viewed 11 November 2022, https://www.geeksforgeeks.org/introduction-to-amortized-analysis/.\nSkiena, S 2012, The Algorithm Design Manual, 2nd edn, Springer Publishing, New York, USA.\nWhat Is A Heap Data Structure In Java 2022, What Is A Heap Data Structure In Java, SoftwareTestingHelp, viewed 27 November 2022, https://www.softwaretestinghelp.com/heap-data-structure-in-java/.\n","date":"2022-12-12T09:44:14+10:30","image":"https://jiajun2001.github.io/p/algorithm-and-data-structure-theory-study/structure_hu_d841b7fdf168fa59.png","permalink":"https://jiajun2001.github.io/p/algorithm-and-data-structure-theory-study/","title":"Algorithm and Data Structure Theory Study"}]